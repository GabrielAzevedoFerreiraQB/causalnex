# Copyright 2019-2020 QuantumBlack Visual Analytics Limited
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND
# NONINFRINGEMENT. IN NO EVENT WILL THE LICENSOR OR OTHER CONTRIBUTORS
# BE LIABLE FOR ANY CLAIM, DAMAGES, OR OTHER LIABILITY, WHETHER IN AN
# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF, OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#
# The QuantumBlack Visual Analytics Limited ("QuantumBlack") name and logo
# (either separately or in combination, "QuantumBlack Trademarks") are
# trademarks of QuantumBlack. The License does not grant you any right or
# license to the QuantumBlack Trademarks. You may not use the QuantumBlack
# Trademarks or any confusingly similar mark as a trademark for your product,
#     or use the QuantumBlack Trademarks in any other manner that might cause
# confusion in the marketplace, including but not limited to in advertising,
# on websites, or on software.
#
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import Dict

import numpy as np
import pandas as pd
import pytest
from pgmpy.models import BayesianModel

from causalnex.network import BayesianNetwork
from causalnex.structure import StructureModel
from causalnex.structure.notears import from_pandas


@pytest.fixture
def train_model() -> StructureModel:
    """
    This Bayesian Model structure will be used in all tests, and all fixtures will adhere to this structure.

    Cause-only nodes: [d, e]
    Effect-only nodes: [a, c]
    Cause / Effect nodes: [b]

            d
         ↙  ↓  ↘
        a ← b → c
            ↑  ↗
            e
    """
    model = StructureModel()
    model.add_edges_from(
        [
            ("b", "a"),
            ("b", "c"),
            ("d", "a"),
            ("d", "c"),
            ("d", "b"),
            ("e", "c"),
            ("e", "b"),
        ]
    )
    return model


@pytest.fixture
def train_model_idx(train_model) -> BayesianModel:
    """
    This Bayesian model is identical to the train_model() fixture, with the exception that node names
    are integers from zero to 1, mapped by:

    {"a": 0, "b": 1, "c": 2, "d": 3, "e": 4}
    """
    model = BayesianModel()
    idx_map = {"a": 0, "b": 1, "c": 2, "d": 3, "e": 4}
    model.add_edges_from([(idx_map[u], idx_map[v]) for u, v in train_model.edges])
    return model


@pytest.fixture
def train_data() -> pd.DataFrame:
    """
    Training data for testing Bayesian Networks. There are 98 samples, with 5 columns:

    - a: {"a", "b", "c", "d"}
    - b: {"x", "y", "z"}
    - c: 0.0 - 100.0
    - d: Boolean
    - e: Boolean

    This data was generated by constructing the Bayesian Model train_model(), and then sampling
    from this structure. Since e and d are both independent of all other nodes, these were sampled first for
    each row (form their respective pre-defined distributions). This then allows the sampling of all further
    variables based on their conditional dependencies.

    The approximate distributions used to sample from can be viewed by inspecting train_data_cpds().

    """

    data_arr = [
        ["a", "x", 73.78658346945414, False, False],
        ["d", "x", 12.765853213346603, False, False],
        ["c", "y", 22.43657132589221, False, False],
        ["a", "x", 4.267744937038964, False, False],
        ["b", "x", 62.87087344904927, False, False],
        ["c", "x", 31.55295196889971, False, False],
        ["a", "x", 37.403388911083965, False, False],
        ["b", "x", 63.171968604247155, False, False],
        ["d", "x", 11.140539452118263, False, False],
        ["d", "x", 0.1555338799942385, True, False],
        ["c", "x", 9.269926225399187, False, True],
        ["b", "z", 75.38846241765208, True, True],
        ["c", "z", 33.10212378889936, False, True],
        ["b", "z", 57.04657630213301, True, True],
        ["b", "x", 72.03855905511072, True, False],
        ["c", "x", 5.106018765399956, False, False],
        ["c", "z", 5.802617702038839, False, True],
        ["c", "x", 17.22538330530506, False, False],
        ["a", "y", 87.05395007052729, False, False],
        ["d", "y", 19.09989481093348, False, False],
        ["c", "x", 4.313272835124353, True, False],
        ["b", "x", 13.660704178900938, True, True],
        ["b", "x", 7.693287813764131, False, False],
        ["c", "y", 32.791770073523246, False, False],
        ["c", "y", 12.039098492465282, False, False],
        ["a", "x", 51.97718339128754, False, False],
        ["d", "x", 8.393970656769238, False, False],
        ["a", "x", 0.3610815726384886, False, False],
        ["a", "y", 35.31788713900731, True, False],
        ["b", "x", 35.84702992379284, False, True],
        ["c", "y", 32.872350426703356, True, False],
        ["a", "x", 21.218746335586868, False, True],
        ["b", "y", 71.5495653029006, True, False],
        ["c", "x", 15.393846082097575, False, False],
        ["d", "y", 4.514559208625406, False, False],
        ["d", "x", 0.704928173400301, False, False],
        ["c", "y", 34.10829794112354, True, False],
        ["d", "x", 6.84602512195673, False, False],
        ["b", "y", 25.43743439885204, False, False],
        ["d", "x", 7.544831467091971, False, False],
        ["d", "x", 13.923699372025073, False, False],
        ["b", "x", 21.493005760070915, False, False],
        ["a", "x", 41.353977640369436, False, False],
        ["c", "z", 10.015835005248583, True, True],
        ["c", "z", 29.40115954319444, False, True],
        ["c", "x", 17.305145945035388, False, False],
        ["b", "x", 57.3687951851441, False, False],
        ["a", "x", 59.31395756039643, False, False],
        ["d", "x", 19.557939187075984, False, False],
        ["d", "y", 15.739556224725082, False, False],
        ["c", "x", 6.850626809845993, True, False],
        ["c", "x", 7.774579861173826, False, False],
        ["c", "x", 20.807136344297092, True, False],
        ["b", "y", 29.406207780312343, False, False],
        ["a", "x", 34.38851648220974, False, False],
        ["d", "x", 1.0951104244381218, True, False],
        ["c", "x", 37.27483338042188, False, False],
        ["b", "x", 15.745994603442064, False, False],
        ["c", "x", 17.78180189764816, False, True],
        ["a", "x", 17.067548428231493, True, False],
        ["c", "x", 26.857320012899727, False, False],
        ["a", "x", 41.0038510689549, False, True],
        ["d", "x", 0.2299684913699096, False, True],
        ["a", "x", 57.35885570158893, True, False],
        ["d", "x", 12.40118443712448, False, False],
        ["c", "x", 22.624550487374112, False, False],
        ["a", "x", 93.08587619178269, False, False],
        ["b", "y", 18.33030505634329, False, False],
        ["a", "z", 64.29945681859853, False, True],
        ["b", "x", 73.66024742961967, False, False],
        ["b", "x", 16.717397443478287, False, True],
        ["c", "y", 4.642615342125205, False, True],
        ["c", "x", 9.431345661106931, False, False],
        ["c", "y", 31.76238774237109, False, False],
        ["c", "y", 3.6961806894707965, False, False],
        ["d", "y", 2.298895066631253, True, False],
        ["d", "y", 13.222298172220462, False, False],
        ["c", "x", 28.301638775451153, False, False],
        ["d", "x", 7.702270580869413, True, False],
        ["a", "y", 41.38492280508702, True, False],
        ["d", "x", 13.047815503255656, True, False],
        ["c", "x", 22.14641490202623, False, False],
        ["b", "z", 43.13007970158368, False, True],
        ["b", "x", 60.09518672623882, True, False],
        ["a", "x", 79.6370082234198, False, False],
        ["d", "x", 16.60880504367762, False, False],
        ["a", "z", 22.88783470451029, False, True],
        ["a", "x", 33.66416643964188, False, False],
        ["b", "y", 69.91787304290465, True, True],
        ["c", "x", 31.941092922567663, True, False],
        ["d", "x", 16.739638908154518, False, False],
        ["a", "z", 11.129589373273108, False, True],
        ["d", "y", 4.96943558614434, True, False],
        ["d", "y", 6.585354730457387, False, False],
        ["d", "x", 9.859942318446954, False, False],
        ["b", "z", 18.541485302271496, False, True],
        ["a", "x", 87.53473074574995, True, False],
        ["a", "z", 59.61068083691302, False, True],
    ]

    data = pd.DataFrame(data_arr, columns=["a", "b", "c", "d", "e"])
    return data


@pytest.fixture
def train_data_discrete(train_data) -> pd.DataFrame:
    """
    train_data in discretised form. This maps "c" into 5 buckets:
    - 0: x < 20
    - 1: 20 <= x < 40
    - 2: 40 <= x < 60
    - 3: 60 <= x < 80
    - 4: 80 <= x
    """
    df = train_data.copy(deep=True)  # type: pd.DataFrame
    df["c"] = df["c"].apply(
        lambda c: 0 if c < 20 else 1 if c < 40 else 2 if c < 60 else 3 if c < 80 else 4
    )
    return df


@pytest.fixture
def train_data_idx(train_data) -> pd.DataFrame:
    """
    train_data in integer index form. This maps each column into values from 0..n
    """

    df = train_data.copy(deep=True)  # type: pd.DataFrame

    df["a"] = df["a"].map({"a": 0, "b": 1, "c": 2, "d": 3})
    df["b"] = df["b"].map({"x": 0, "y": 1, "z": 2})
    df["c"] = df["c"].apply(
        lambda c: 0 if c < 20 else 1 if c < 40 else 2 if c < 60 else 3 if c < 80 else 4
    )
    df["d"] = df["d"].map({True: 1, False: 0})
    df["e"] = df["e"].map({True: 1, False: 0})
    return df


@pytest.fixture
def train_data_idx_cpds(train_data_idx) -> Dict[str, np.ndarray]:
    """Conditional probability distributions of train_data in the train_model"""

    return create_cpds(train_data_idx)


@pytest.fixture
def train_data_discrete_cpds(train_data_discrete) -> Dict[str, np.ndarray]:
    """Conditional probability distributions of train_data in the train_model"""

    return create_cpds(train_data_discrete)


@pytest.fixture
def train_data_discrete_cpds_k2(train_data_discrete) -> Dict[str, np.ndarray]:
    """Conditional probability distributions of train_data in the train_model"""

    return create_cpds(train_data_discrete, pc=1)


def create_cpds(data, pc=0):

    df = data.copy(deep=True)  # type: pd.DataFrame

    df_vals = {col: list(df[col].unique()) for col in df.columns}
    for _, vals in df_vals.items():
        vals.sort()

    cpd_a = np.array(
        [
            [
                (len(df[(df["a"] == a) & (df["b"] == b) & (df["d"] == d)]) + pc)
                / (len(df[(df["b"] == b) & (df["d"] == d)]) + (pc * len(df_vals["a"])))
                for b in df_vals["b"]
                for d in df_vals["d"]
            ]
            for a in df_vals["a"]
        ]
    )

    cpd_b = np.array(
        [
            [
                (len(df[(df["b"] == b) & (df["d"] == d) & (df["e"] == e)]) + pc)
                / (len(df[(df["d"] == d) & (df["e"] == e)]) + (pc * len(df_vals["b"])))
                for d in df_vals["d"]
                for e in df_vals["e"]
            ]
            for b in df_vals["b"]
        ]
    )

    cpd_c = np.array(
        [
            [
                (
                    (
                        len(
                            df[
                                (df["c"] == c)
                                & (df["b"] == b)
                                & (df["d"] == d)
                                & (df["e"] == e)
                            ]
                        )
                        + pc
                    )
                    / (
                        len(df[(df["b"] == b) & (df["d"] == d) & (df["e"] == e)])
                        + (pc * len(df_vals["c"]))
                    )
                )
                if not df[(df["b"] == b) & (df["d"] == d) & (df["e"] == e)].empty
                else (1 / len(df_vals["c"]))
                for b in df_vals["b"]
                for d in df_vals["d"]
                for e in df_vals["e"]
            ]
            for c in df_vals["c"]
        ]
    )

    cpd_d = np.array(
        [
            [(len(df[df["d"] == d]) + pc) / (len(df) + (pc * len(df_vals["d"])))]
            for d in df_vals["d"]
        ]
    )

    cpd_e = np.array(
        [
            [(len(df[df["e"] == e]) + pc) / (len(df) + (pc * len(df_vals["e"])))]
            for e in df_vals["e"]
        ]
    )

    return {"a": cpd_a, "b": cpd_b, "c": cpd_c, "d": cpd_d, "e": cpd_e}


@pytest.fixture
def train_data_idx_marginals(train_data_idx_cpds):

    return create_marginals(
        train_data_idx_cpds,
        {
            "a": list(range(4)),
            "b": list(range(3)),
            "c": list(range(5)),
            "d": list(range(2)),
            "e": list(range(2)),
        },
    )


@pytest.fixture
def train_data_discrete_marginals(train_data_discrete_cpds):

    return create_marginals(
        train_data_discrete_cpds,
        {
            "a": ["a", "b", "c", "d"],
            "b": ["x", "y", "z"],
            "c": [0, 1, 2, 3, 4],
            "d": [False, True],
            "e": [False, True],
        },
    )


def create_marginals(cpds, data_vals):
    cpd_d = cpds["d"]
    p_d = {i: cpd_d[i, 0] for i in range(len(cpd_d))}

    cpd_e = cpds["e"]
    p_e = {i: cpd_e[i, 0] for i in range(len(cpd_e))}

    cpd_b = cpds["b"]
    c_b = np.array(
        [
            [p_d[d] * p_e[e] for d in range(len(cpd_d)) for e in range(len(cpd_e))]
            for _ in range(len(cpd_b))
        ]
    )
    p_b = dict(enumerate((c_b * cpd_b).sum(axis=1)))

    cpd_a = cpds["a"]
    c_a = np.array(
        [
            [p_b[b] * p_d[d] for b in range(len(cpd_b)) for d in range(len(cpd_d))]
            for _ in range(len(cpd_a))
        ]
    )
    p_a = dict(enumerate((c_a * cpd_a).sum(axis=1)))

    cpd_c = cpds["c"]
    c_c = np.array(
        [
            [
                p_b[b] * p_d[d] * p_e[e]
                for b in range(len(cpd_b))
                for d in range(len(cpd_d))
                for e in range(len(cpd_e))
            ]
            for _ in range(len(cpd_c))
        ]
    )
    p_c = dict(enumerate((c_c * cpd_c).sum(axis=1)))

    marginals = {
        "a": {data_vals["a"][k]: v for k, v in p_a.items()},
        "b": {data_vals["b"][k]: v for k, v in p_b.items()},
        "c": {data_vals["c"][k]: v for k, v in p_c.items()},
        "d": {data_vals["d"][k]: v for k, v in p_d.items()},
        "e": {data_vals["e"][k]: v for k, v in p_e.items()},
    }

    return marginals


@pytest.fixture
def test_data_c() -> pd.DataFrame:
    """Test data created so that C should be perfectly predicted based on train_data_cpds.

    Given the two independent variables are set randomly (d, e), all other variables are set to be
    from the category with maximum likelihood in train_data_cpds"""

    data_arr = [
        ["a", "x", 1, False, False],
        ["b", "x", 2, False, True],
        ["c", "x", 3, True, False],
        ["d", "x", 4, True, True],
        ["d", "y", 1, False, False],
        ["c", "y", 2, False, True],
        ["b", "y", 23, True, False],
        ["a", "y", 64, True, True],
        ["c", "z", 1, False, False],
        ["a", "z", 2, False, True],
        ["d", "z", 3, True, False],
        ["b", "z", 0, True, True],
    ]

    data = pd.DataFrame(data_arr, columns=["a", "b", "c", "d", "e"])
    return data


@pytest.fixture
def test_data_c_discrete(test_data_c) -> pd.DataFrame:
    """Test data C that has been discretised (see train_data_discrete)"""
    df = test_data_c.copy(deep=True)  # type: pd.DataFrame
    df["c"] = df["c"].apply(
        lambda c: 0 if c < 20 else 1 if c < 40 else 2 if c < 60 else 3 if c < 80 else 4
    )
    return df


@pytest.fixture
def test_data_c_likelihood(train_data_discrete_cpds) -> pd.DataFrame:
    """Marginal likelihoods for train_data in train_model"""

    # Known bug in pylint with generated Dict: https://github.com/PyCQA/pylint/issues/1498
    data_arr = [
        [
            (train_data_discrete_cpds["c"])[  # pylint: disable=unsubscriptable-object
                y, x
            ]
            for y in range(
                len(
                    # pylint: disable=unsubscriptable-object
                    train_data_discrete_cpds["c"]
                )
            )
        ]
        for x in range(len(train_data_discrete_cpds["c"][0]))
    ]

    likelihood = pd.DataFrame(data_arr, columns=["c_0", "c_1", "c_2", "c_3", "c_4"])
    return likelihood


@pytest.fixture
def bn(train_data_idx, train_data_discrete) -> BayesianNetwork:
    return BayesianNetwork(
        from_pandas(train_data_idx, w_threshold=0.3)
    ).fit_node_states_and_cpds(train_data_discrete)


@pytest.fixture
def adjacency_mat_num_stability() -> np.ndarray:
    """
    Adjacency matrix for training structure learning algorithms
    """

    W = np.array(
        [
            [0.0, 0.0, 0.0, 0.0, 0.0],
            [-0.6, 0.0, 0.0, 0.0, 1.27],
            [0.9, 0.0, 0.0, 0.0, -0.98],
            [0.0, -0.89, 1.37, 0.0, 0.0],
            [1.74, 0.0, 0.0, 0.0, 0.0],
        ]
    )
    return W
